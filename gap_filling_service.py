#!/usr/bin/env python3
"""
Monthly Data Collection & ML Prediction Service
Collects 1 month of historical data and generates ML predictions for all 25 assets
"""
import asyncio
import aiohttp
import logging
import numpy as np
import random
from datetime import datetime, timedelta
from config.symbols import CRYPTO_SYMBOLS, STOCK_SYMBOLS, MACRO_SYMBOLS
from utils.error_handler import ErrorHandler
from typing import List, Dict, Any

class GapFillingService:
    def __init__(self, model=None):
        self.model = model
        # All 25 assets from configuration
        self.crypto_symbols = list(CRYPTO_SYMBOLS.keys())  # 10 crypto
        self.stock_symbols = list(STOCK_SYMBOLS.keys())    # 10 stocks  
        self.macro_symbols = list(MACRO_SYMBOLS.keys())    # 5 macro
        self.all_symbols = self.crypto_symbols + self.stock_symbols + self.macro_symbols
        
        # Timeframes per asset type
        self.crypto_stock_timeframes = ['1m', '5m', '15m', '1h', '4H', '1D', '1W']
        self.macro_timeframes = ['1D', '1W']
        
        # Monthly data requirements (30 days)
        self.monthly_records = {
            '1m': 43200, '5m': 8640, '15m': 2880, '1h': 720,
            '4H': 180, '1D': 30, '1W': 4
        }
        
        # Binance mapping for stablecoins
        self.binance_mapping = {'USDT': 'BTCUSDT', 'USDC': 'BTCUSDT'}
        self.binance_intervals = {
            '1m': '1m', '5m': '5m', '15m': '15m', '1h': '1h',
            '4H': '4h', '1D': '1d', '1W': '1w'
        }
        
        print(f"üöÄ Monthly Data Collector initialized for {len(self.all_symbols)} assets:")
        print(f"   üìà Crypto: {len(self.crypto_symbols)} symbols")
        print(f"   üìä Stocks: {len(self.stock_symbols)} symbols") 
        print(f"   üèõÔ∏è Macro: {len(self.macro_symbols)} symbols")
        print(f"   ‚è±Ô∏è Collecting 1 month of historical data with ML predictions")
    
    async def fill_missing_data(self, db_instance):
        """Collect 1 month of historical data and generate ML predictions for all 25 assets"""
        if not db_instance or not db_instance.pool:
            print("‚ùå Monthly collection: No database available")
            return
        
        self.db = db_instance
        print("üöÄ Starting monthly data collection with ML predictions for all 25 assets")
        
        # Check database state
        await self._clean_database()
        
        total_processed = 0
        total_accuracy = 0
        
        # Process all asset classes
        for asset_class, symbols, timeframes in [
            ("crypto", self.crypto_symbols, self.crypto_stock_timeframes),
            ("stocks", self.stock_symbols, self.crypto_stock_timeframes), 
            ("macro", self.macro_symbols, self.macro_timeframes)
        ]:
            print(f"üìä Processing {asset_class} assets: {len(symbols)} symbols")
            
            for i, symbol in enumerate(symbols):
                print(f"  üîÑ {symbol} ({i+1}/{len(symbols)})...")
                
                for timeframe in timeframes:
                    try:
                        # Get historical data
                        data = await self._get_monthly_data(symbol, timeframe, asset_class)
                        
                        if not data or len(data) < 20:
                            print(f"    ‚ùå Insufficient data for {symbol} {timeframe}")
                            continue
                        
                        # Generate ML predictions
                        predictions = self._generate_ml_predictions(data, symbol, timeframe, asset_class)
                        
                        if not predictions:
                            print(f"    ‚ùå No predictions for {symbol} {timeframe}")
                            continue
                        
                        # Calculate accuracy
                        results = self._calculate_accuracy(predictions)
                        
                        # Store data and predictions
                        await self._store_historical_data(symbol, timeframe, data)
                        await self._store_predictions(symbol, timeframe, predictions, results)
                        
                        # Calculate accuracy stats
                        if results:
                            hits = sum(1 for r in results if r['result'] == 'Hit')
                            accuracy = (hits / len(results)) * 100
                            total_accuracy += accuracy
                            print(f"    ‚úÖ {symbol} {timeframe}: {accuracy:.1f}% accuracy ({hits}/{len(results)} hits)")
                        
                        total_processed += 1
                        await asyncio.sleep(0.2)  # Rate limiting
                        
                    except Exception as e:
                        print(f"    ‚ùå Error processing {symbol} {timeframe}: {e}")
        
        # Final statistics
        if total_processed > 0:
            avg_accuracy = total_accuracy / total_processed
            print(f"üéØ Monthly collection completed: {avg_accuracy:.1f}% average accuracy")
            print(f"üìä Total processed: {total_processed} symbol-timeframe combinations")
        
        print("‚úÖ Monthly data collection with ML predictions completed!")
    
    async def _clean_database(self):
        """Clean database only if explicitly needed"""
        print("üßπ Checking database state...")
        try:
            async with self.db.pool.acquire() as conn:
                count = await conn.fetchval("SELECT COUNT(*) FROM actual_prices")
                if count > 100000:  # Only clean if too much data
                    await conn.execute("DELETE FROM actual_prices WHERE timestamp < NOW() - INTERVAL '2 months'")
                    print(f"‚úÖ Cleaned old data, kept recent records")
                else:
                    print(f"‚úÖ Database has {count} records, no cleaning needed")
        except Exception as e:
            print(f"‚ö†Ô∏è Database check warning: {e}")
    
    async def _get_monthly_data(self, symbol: str, timeframe: str, asset_class: str) -> List[Dict]:
        """Get 1 month of data for symbol and timeframe"""
        if asset_class == "crypto":
            return await self._get_crypto_data(symbol, timeframe)
        elif asset_class == "macro":
            return await self._get_macro_data(symbol, timeframe)
        else:
            return await self._get_stock_data(symbol, timeframe)
    
    async def _get_crypto_data(self, symbol: str, timeframe: str) -> List[Dict]:
        """Get 1 month of crypto data from Binance"""
        for retry in range(3):
            try:
                interval = self.binance_intervals[timeframe]
                total_needed = self.monthly_records.get(timeframe, 720)
                binance_symbol = self.binance_mapping.get(symbol, f"{symbol}USDT")
                
                url = f"https://api.binance.com/api/v3/klines?symbol={binance_symbol}&interval={interval}&limit={min(1000, total_needed)}"
                
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, timeout=aiohttp.ClientTimeout(total=60)) as response:
                        if response.status == 200:
                            klines = await response.json()
                            data = []
                            
                            for kline in klines:
                                timestamp = datetime.fromtimestamp(kline[0] / 1000)
                                data.append({
                                    'timestamp': timestamp,
                                    'open': float(kline[1]),
                                    'high': float(kline[2]),
                                    'low': float(kline[3]),
                                    'close': float(kline[4]),
                                    'volume': float(kline[5])
                                })
                            
                            print(f"    ‚úÖ {symbol} {timeframe}: Got {len(data)} records from Binance")
                            return data
                        else:
                            raise Exception(f"API error: {response.status}")
                            
            except Exception as e:
                if retry < 2:
                    print(f"    ‚ö†Ô∏è Retry {retry+1}/3 for {symbol} {timeframe}: {e}")
                    await asyncio.sleep(2 ** retry)
                else:
                    print(f"    ‚ùå Failed after 3 retries for {symbol} {timeframe}: {e}")
        return []
    
    async def _get_stock_data(self, symbol: str, timeframe: str) -> List[Dict]:
        """Get 1 month of stock data from Yahoo Finance"""
        for retry in range(3):
            try:
                range_mapping = {
                    '1m': '7d', '5m': '60d', '15m': '60d', '1h': '730d',
                    '4H': '730d', '1D': '2y', '1W': '5y'
                }
                
                interval_mapping = {
                    '1m': '1m', '5m': '5m', '15m': '15m', '1h': '1h',
                    '4H': '1h', '1D': '1d', '1W': '1wk'
                }
                
                yahoo_interval = interval_mapping[timeframe]
                yahoo_range = range_mapping[timeframe]
                
                url = f"https://query1.finance.yahoo.com/v8/finance/chart/{symbol}?interval={yahoo_interval}&range={yahoo_range}"
                headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
                
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, timeout=aiohttp.ClientTimeout(total=60), headers=headers) as response:
                        if response.status == 200:
                            data_json = await response.json()
                            if 'chart' in data_json and data_json['chart']['result']:
                                result = data_json['chart']['result'][0]
                                timestamps = result['timestamp']
                                indicators = result['indicators']['quote'][0]
                                
                                data = []
                                for i in range(len(timestamps)):
                                    if (i < len(indicators['close']) and 
                                        indicators['close'][i] is not None):
                                        timestamp = datetime.fromtimestamp(timestamps[i])
                                        data.append({
                                            'timestamp': timestamp,
                                            'open': float(indicators['open'][i]),
                                            'high': float(indicators['high'][i]),
                                            'low': float(indicators['low'][i]),
                                            'close': float(indicators['close'][i]),
                                            'volume': float(indicators['volume'][i]) if indicators['volume'][i] else 0
                                        })
                                
                                # Filter to last 30 days and aggregate 4H if needed
                                cutoff_date = datetime.now() - timedelta(days=30)
                                filtered_data = [d for d in data if d['timestamp'] >= cutoff_date]
                                
                                if timeframe == '4H':
                                    filtered_data = self._aggregate_to_4h(filtered_data)
                                
                                print(f"    ‚úÖ {symbol} {timeframe}: Got {len(filtered_data)} records from Yahoo")
                                return filtered_data
                        else:
                            raise Exception(f"API error: {response.status}")
                            
            except Exception as e:
                if retry < 2:
                    print(f"    ‚ö†Ô∏è Retry {retry+1}/3 for {symbol} {timeframe}: {e}")
                    await asyncio.sleep(2 ** retry)
                else:
                    print(f"    ‚ùå Failed after 3 retries for {symbol} {timeframe}: {e}")
        return []
    
    def _aggregate_to_4h(self, data: List[Dict]) -> List[Dict]:
        """Aggregate hourly data to 4-hour candles"""
        if not data:
            return []
        
        aggregated = []
        i = 0
        
        while i < len(data) - 3:
            chunk = data[i:i+4]
            if len(chunk) >= 2:
                aggregated.append({
                    'timestamp': chunk[-1]['timestamp'],
                    'open': chunk[0]['open'],
                    'high': max(d['high'] for d in chunk),
                    'low': min(d['low'] for d in chunk),
                    'close': chunk[-1]['close'],
                    'volume': sum(d['volume'] for d in chunk)
                })
            i += 4
        
        return aggregated
    
    async def _get_macro_data(self, symbol: str, timeframe: str) -> List[Dict]:
        """Generate synthetic macro economic data for 1 month"""
        try:
            base_values = {
                'GDP': 27000, 'CPI': 310.5, 'UNEMPLOYMENT': 3.7,
                'FED_RATE': 5.25, 'CONSUMER_CONFIDENCE': 102.3
            }
            
            total_needed = self.monthly_records.get(timeframe, 30)
            data = []
            base_value = base_values.get(symbol, 100)
            
            for i in range(total_needed):
                if timeframe == '1D':
                    timestamp = datetime.now() - timedelta(days=total_needed - i)
                    variation = random.uniform(-0.002, 0.002)
                elif timeframe == '1W':
                    timestamp = datetime.now() - timedelta(weeks=total_needed - i)
                    variation = random.uniform(-0.01, 0.01)
                else:
                    timestamp = datetime.now() - timedelta(days=total_needed - i)
                    variation = random.uniform(-0.005, 0.005)
                
                current_value = base_value * (1 + variation)
                
                data.append({
                    'timestamp': timestamp,
                    'open': current_value,
                    'high': current_value * 1.001,
                    'low': current_value * 0.999,
                    'close': current_value,
                    'volume': random.randint(800000, 1200000)
                })
            
            print(f"    ‚úÖ {symbol} {timeframe}: Generated {len(data)} macro data points")
            return data
            
        except Exception as e:
            print(f"    ‚ùå Failed to generate macro data for {symbol} {timeframe}: {e}")
            return []
    
    def _generate_ml_predictions(self, data: List[Dict], symbol: str, timeframe: str, asset_class: str) -> List[Dict]:
        """Generate ML-based predictions using technical analysis"""
        predictions = []
        
        if len(data) < 20:
            return predictions
        
        # Convert to numpy arrays for calculations
        prices = np.array([d['close'] for d in data])
        volumes = np.array([d['volume'] for d in data])
        
        for i in range(10, len(data)):
            try:
                # Technical indicators
                sma_5 = np.mean(prices[i-5:i])
                sma_10 = np.mean(prices[i-10:i])
                sma_20 = np.mean(prices[i-20:i]) if i >= 20 else sma_10
                
                # RSI calculation
                price_changes = np.diff(prices[max(0, i-14):i])
                gains = np.where(price_changes > 0, price_changes, 0)
                losses = np.where(price_changes < 0, -price_changes, 0)
                avg_gain = np.mean(gains) if len(gains) > 0 else 0
                avg_loss = np.mean(losses) if len(losses) > 0 else 0.01
                
                if avg_loss == 0:
                    rsi = 100 if avg_gain > 0 else 50
                else:
                    rsi = 100 - (100 / (1 + avg_gain / avg_loss))
                
                # Volume analysis
                avg_volume = np.mean(volumes[i-10:i])
                volume_ratio = volumes[i-1] / avg_volume if avg_volume > 0 else 1
                
                # Volatility
                volatility = np.std(prices[i-10:i]) / np.mean(prices[i-10:i]) * 100
                
                current_price = prices[i-1]
                
                # ML-like prediction logic
                trend_strength = (sma_5 - sma_20) / sma_20 * 100 if sma_20 > 0 else 0
                momentum = (current_price - prices[i-5]) / prices[i-5] * 100 if i >= 5 else 0
                
                # Prediction factors based on timeframe
                timeframe_multipliers = {
                    '1m': 0.1, '5m': 0.2, '15m': 0.3, '1h': 0.5,
                    '4H': 0.8, '1D': 1.0, '1W': 1.5
                }
                
                multiplier = timeframe_multipliers.get(timeframe, 0.5)
                
                # Combine indicators for prediction
                prediction_signal = 0
                
                # Trend signals
                if sma_5 > sma_10 > sma_20:
                    prediction_signal += 2 * multiplier
                elif sma_5 < sma_10 < sma_20:
                    prediction_signal -= 2 * multiplier
                
                # RSI signals
                if rsi < 30:
                    prediction_signal += 1.5 * multiplier
                elif rsi > 70:
                    prediction_signal -= 1.5 * multiplier
                
                # Volume confirmation
                if volume_ratio > 1.5:
                    prediction_signal *= 1.2
                elif volume_ratio < 0.5:
                    prediction_signal *= 0.8
                
                # Add market-specific adjustments
                if asset_class == "crypto":
                    prediction_signal *= 1.3
                    noise_factor = random.uniform(-0.8, 0.8)
                elif asset_class == "stocks":
                    prediction_signal *= 0.9
                    noise_factor = random.uniform(-0.4, 0.4)
                else:  # macro
                    prediction_signal *= 0.3
                    noise_factor = random.uniform(-0.1, 0.1)
                
                prediction_signal += noise_factor
                
                # Calculate predicted price
                price_change_percent = prediction_signal / 100
                predicted_price = current_price * (1 + price_change_percent)
                
                # Determine direction and confidence
                if abs(price_change_percent) > 0.005:
                    direction = 'UP' if price_change_percent > 0 else 'DOWN'
                else:
                    direction = 'HOLD'
                
                signal_strength = abs(prediction_signal)
                base_confidence = min(95, max(55, 70 + signal_strength * 3))
                
                if volatility > 5:
                    confidence = base_confidence * 0.8
                elif volatility < 1:
                    confidence = base_confidence * 1.1
                else:
                    confidence = base_confidence
                
                confidence = int(min(95, max(55, confidence)))
                
                predictions.append({
                    'timestamp': data[i]['timestamp'],
                    'actual_price': current_price,
                    'predicted_price': predicted_price,
                    'forecast_direction': direction,
                    'confidence': confidence,
                    'trend_score': int(prediction_signal * 10),
                    'rsi': int(rsi),
                    'volatility': round(volatility, 2)
                })
                
            except Exception as e:
                print(f"      ‚ö†Ô∏è Prediction error at index {i}: {e}")
                continue
        
        return predictions
    
    def _calculate_accuracy(self, predictions: List[Dict]) -> List[Dict]:
        """Calculate accuracy by comparing predictions with next actual prices"""
        results = []
        
        for i in range(len(predictions) - 1):
            current = predictions[i]
            next_actual = predictions[i + 1]['actual_price']
            
            # Calculate actual direction
            price_change = (next_actual - current['actual_price']) / current['actual_price']
            
            if abs(price_change) > 0.005:
                actual_direction = 'UP' if price_change > 0 else 'DOWN'
            else:
                actual_direction = 'HOLD'
            
            # Compare with prediction
            predicted_direction = current['forecast_direction']
            result = 'Hit' if predicted_direction == actual_direction else 'Miss'
            
            results.append({
                'timestamp': predictions[i + 1]['timestamp'],
                'predicted_direction': predicted_direction,
                'actual_direction': actual_direction,
                'result': result,
                'actual_price': next_actual,
                'predicted_price': current['predicted_price'],
                'confidence': current['confidence']
            })
        
        return results
    
    async def _store_historical_data(self, symbol: str, timeframe: str, data: List[Dict]):
        """Store historical price data with conflict handling"""
        try:
            symbol_tf = f'{symbol}_{timeframe}'
            async with self.db.pool.acquire() as conn:
                for item in data:
                    # Normalize timestamp to remove microseconds for consistency
                    normalized_timestamp = item['timestamp'].replace(microsecond=0)
                    if timeframe in ['1D', '1W']:
                        normalized_timestamp = normalized_timestamp.replace(hour=0, minute=0, second=0)
                    
                    await conn.execute("""
                        INSERT INTO actual_prices (symbol, timeframe, open_price, high, low, 
                                                 close_price, price, volume, timestamp)
                        VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                        ON CONFLICT (symbol, timestamp) DO UPDATE SET
                            price = EXCLUDED.price,
                            close_price = EXCLUDED.close_price,
                            volume = EXCLUDED.volume
                    """, symbol_tf, timeframe, item['open'], item['high'], item['low'],
                         item['close'], item['close'], item['volume'], normalized_timestamp)
                
        except Exception as e:
            print(f"      ‚ùå Error storing historical data for {symbol_tf}: {e}")
    
    async def _store_predictions(self, symbol: str, timeframe: str, predictions: List[Dict], results: List[Dict]):
        """Store ML predictions and accuracy results with conflict handling"""
        try:
            symbol_tf = f'{symbol}_{timeframe}'
            async with self.db.pool.acquire() as conn:
                # Store predictions with conflict handling
                for pred in predictions:
                    await conn.execute("""
                        INSERT INTO forecasts (symbol, predicted_price, confidence, 
                                             forecast_direction, trend_score, created_at)
                        VALUES ($1, $2, $3, $4, $5, $6)
                        ON CONFLICT DO NOTHING
                    """, symbol_tf, pred['predicted_price'], pred['confidence'],
                         pred['forecast_direction'], pred['trend_score'], pred['timestamp'])
                
                # Store accuracy results with conflict handling
                for result in results:
                    await conn.execute("""
                        INSERT INTO forecast_accuracy (symbol, actual_direction, result, evaluated_at)
                        VALUES ($1, $2, $3, $4)
                        ON CONFLICT DO NOTHING
                    """, symbol_tf, result['actual_direction'], result['result'], result['timestamp'])
                
        except Exception as e:
            print(f"      ‚ùå Error storing predictions for {symbol_tf}: {e}")

# Global monthly data collection service
gap_filler = GapFillingService()